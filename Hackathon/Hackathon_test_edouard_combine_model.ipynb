{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/lib64/python2.7/site-packages\r\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python2.7/site-packages (from keras)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python2.7/site-packages (from keras)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/lib64/python2.7/site-packages (from keras)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/lib64/python2.7/site-packages (from keras)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "PATH_DATA = 'data/train/eightieth.h5'\n",
    "PATH_PREDICT_WITHOUT_GT = 'data/pred_students/pred_eighties_from_half_1_without_gt.h5'\n",
    "PATH_SUBMIT_1 = 'test_combine_1.h5'\n",
    "PATH_SUBMIT_2 = 'test_combine_2.h5'\n",
    "PATH_SUBMIT_3 = 'test_combine_3.h5'\n",
    "PATH_SUBMIT_4 = 'test_combine_4.h5'\n",
    "PATH_SUBMIT_5 = 'test_combine_5.h5'\n",
    "PATH_PREDICT_WITH_GT = 'data/pred_teachers/pred_eighties_from_half_1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, Reshape, Dropout\n",
    "import keras.layers.normalization \n",
    "from keras.callbacks import Callback\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs(h5_path):\n",
    "    f = h5.File(h5_path)\n",
    "    return range(len(f['S2']))\n",
    "\n",
    "def shuffle_idx(sample_idxs):\n",
    "    return list(np.random.permutation(sample_idxs))\n",
    "\n",
    "def split_train_val(sample_idxs, proportion):\n",
    "    n_samples = len(sample_idxs)\n",
    "    return sample_idxs[:int((1.-proportion)*n_samples)], sample_idxs[int((1.-proportion)*n_samples):]\n",
    "\n",
    "def get_batch_count(idxs, batch_size):\n",
    "    batch_count = int(len(idxs)//batch_size)\n",
    "    remained_samples = len(idxs)%batch_size\n",
    "    if remained_samples > 0:\n",
    "        batch_count += 1\n",
    "\n",
    "    return batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = get_idxs(PATH_DATA)\n",
    "shuffled_idxs = shuffle_idx(idxs)\n",
    "train_idxs, val_idxs = split_train_val(shuffled_idxs, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import cv2\n",
    "\n",
    "\n",
    "def generator_fft(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    while True : \n",
    "        idxs = shuffle_idx(idxs)\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = []\n",
    "            Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "            batch = f['S2'][batch_idxs, :,:,:]\n",
    "            for bb in range(len(batch)):\n",
    "                patch = batch[bb,:,:,:]\n",
    "                fft2 = np.zeros((16,16,4))\n",
    "                fft2[:,:,0] = np.real(np.fft.fft2(batch[bb,:,:,0]))\n",
    "                fft2[:,:,1] = np.real(np.fft.fft2(batch[bb,:,:,1]))\n",
    "                fft2[:,:,2] = np.real(np.fft.fft2(batch[bb,:,:,2]))\n",
    "                fft2[:,:,3] = np.real(np.fft.fft2(batch[bb,:,:,3]))\n",
    "                X.append(fft2)\n",
    "                \n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_dwt(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    while True : \n",
    "        idxs = shuffle_idx(idxs)\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = []\n",
    "            Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "            batch = f['S2'][batch_idxs, :,:,:]\n",
    "            for bb in range(len(batch)):\n",
    "                patch = batch[bb,:,:,:]\n",
    "                \n",
    "                # dwt2 for each chan\n",
    "                cA0, (cD0, cV0, cH0) = pywt.dwt2(batch[bb,:,:,0], 'haar')\n",
    "                cA1, (cD1, cV1, cH1) = pywt.dwt2(batch[bb,:,:,1], 'haar')\n",
    "                cA2, (cD2, cV2, cH2) = pywt.dwt2(batch[bb,:,:,2], 'haar')\n",
    "                cA3, (cD3, cV3, cH3) = pywt.dwt2(batch[bb,:,:,3], 'haar')\n",
    "                \n",
    "                dwt2 = np.zeros((16,16,4))\n",
    "                dwt2[:,:,0] = np.concatenate((np.concatenate((cA0, cD0), axis=1), np.concatenate((cV0, cH0), axis=1)), axis=0)\n",
    "                dwt2[:,:,1] = np.concatenate((np.concatenate((cA1, cD1), axis=1), np.concatenate((cV1, cH1), axis=1)), axis=0)\n",
    "                dwt2[:,:,2] = np.concatenate((np.concatenate((cA2, cD2), axis=1), np.concatenate((cV2, cH2), axis=1)), axis=0)\n",
    "                dwt2[:,:,3] = np.concatenate((np.concatenate((cA3, cD3), axis=1), np.concatenate((cV3, cH3), axis=1)), axis=0)\n",
    "                X.append(dwt2)\n",
    "                \n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_patch(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    while True : \n",
    "        idxs = shuffle_idx(idxs)\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = []\n",
    "            Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "            batch = f['S2'][batch_idxs, :,:,:]\n",
    "            for bb in range(len(batch)):\n",
    "                patch = batch[bb,:,:,:]\n",
    "                X.append(patch)\n",
    "                \n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_hist(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    while True : \n",
    "        idxs = shuffle_idx(idxs)\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = []\n",
    "            Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "            batch = f['S2'][batch_idxs, :,:,:]\n",
    "            for bb in range(len(batch)):\n",
    "                patch = batch[bb,:,:,:]\n",
    "                band_normalized = []\n",
    "                for i in range(4):\n",
    "                    a = patch[:,:,i].flatten()\n",
    "                    band_normalized.append((255*((a - np.min(a)) / ( np.max(a) - np.min(a)))).astype(int))\n",
    "                \n",
    "                h0, bins = np.histogram(band_normalized[0], bins=range(256))\n",
    "                h1, bins = np.histogram(band_normalized[1], bins=range(256))\n",
    "                h2, bins = np.histogram(band_normalized[2], bins=range(256))\n",
    "                h3, bins = np.histogram(band_normalized[3], bins=range(256))\n",
    "                h = np.concatenate((h0, h1, h2, h3), axis=0)\n",
    "                X.append(h)\n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        # store the number of points and radius\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    " \n",
    "    def describe(self, image, eps=1e-7):\n",
    "        # compute the Local Binary Pattern representation\n",
    "        # of the image, and then use the LBP representation\n",
    "        # to build the histogram of patterns\n",
    "        lbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "            self.radius, method=\"uniform\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(),\n",
    "            bins=np.arange(0, self.numPoints + 3),\n",
    "            range=(0, self.numPoints + 2))\n",
    "\n",
    "        # normalize the histogram\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "\n",
    "        # return the histogram of Local Binary Patterns\n",
    "        return hist\n",
    "\n",
    "def generator_texture(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    desc = LocalBinaryPatterns(32, 12)\n",
    "    while True : \n",
    "        idxs = shuffle_idx(idxs)\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = []\n",
    "            Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "            batch = f['S2'][batch_idxs, :,:,:]\n",
    "            for bb in range(len(batch)):\n",
    "                patch = batch[bb,:,:,:]\n",
    "                gray = cv2.cvtColor(batch[bb,:,:,:], cv2.COLOR_BGR2GRAY)\n",
    "                hist = desc.describe(gray)\n",
    "                X.append(hist)\n",
    "                \n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.util import img_as_float\n",
    "from skimage.filters import gabor_kernel\n",
    "from scipy import ndimage as nd\n",
    "def generator_gabor(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    # prepare filter bank kernels\n",
    "    kernels = []\n",
    "    for theta in range(4):\n",
    "        theta = theta / 4. * np.pi\n",
    "        for sigma in (1, 3):\n",
    "            for frequency in (0.05, 0.25):\n",
    "                kernel = np.real(gabor_kernel(frequency, theta=theta,\n",
    "                                            sigma_x=sigma, sigma_y=sigma))\n",
    "                kernels.append(kernel)\n",
    "\n",
    "    while True : \n",
    "        idxs = shuffle_idx(idxs)\n",
    "        batch_count = get_batch_count(idxs, batch_size)\n",
    "        for b in range(batch_count):\n",
    "            batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "            batch_idxs = sorted(batch_idxs)\n",
    "            X = []\n",
    "            Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "            batch = f['S2'][batch_idxs, :,:,:]\n",
    "            for bb in range(len(batch)):\n",
    "                patch = batch[bb,:,:,:]\n",
    "                gray = cv2.cvtColor(batch[bb,:,:,:], cv2.COLOR_BGR2GRAY)\n",
    "                filtered = []\n",
    "                for i in range(len(kernels)):\n",
    "                    filtered.append(nd.convolve(gray, kernels[i]))\n",
    "                \n",
    "                X.append(filtered)\n",
    "            yield np.array(X), keras.utils.np_utils.to_categorical(np.array(Y), 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele 1 : patch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850 1463\n",
      "(32, 16, 16, 4)\n"
     ]
    }
   ],
   "source": [
    "train_gen_patch = generator_patch(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen_patch = generator_patch(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)\n",
    "print(train_batch_count, val_batch_count)\n",
    "print(np.shape(train_gen_patch.__next__()[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 16, 16, 4)         16        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        592       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 23)                2967      \n",
      "=================================================================\n",
      "Total params: 846,039\n",
      "Trainable params: 846,031\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (16,16,4)\n",
    "model_patch = Sequential()\n",
    "model_patch.add(BatchNormalization(input_shape=input_shape))\n",
    "model_patch.add(Conv2D(16, kernel_size=(3, 3),activation='relu'))\n",
    "model_patch.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_patch.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_patch.add(Dropout(0.25))\n",
    "model_patch.add(Flatten())\n",
    "model_patch.add(Dense(128, activation='relu'))\n",
    "model_patch.add(Dropout(0.5))\n",
    "model_patch.add(Dense(23, activation='softmax'))\n",
    "\n",
    "model_patch.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_patch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "183/182 [==============================] - 17s 91ms/step - loss: 1.5080 - acc: 0.4624 - val_loss: 1.2263 - val_acc: 0.5421\n",
      "Epoch 2/10\n",
      "183/182 [==============================] - 12s 67ms/step - loss: 1.3120 - acc: 0.5106 - val_loss: 1.2361 - val_acc: 0.5285\n",
      "Epoch 3/10\n",
      "183/182 [==============================] - 12s 66ms/step - loss: 1.2828 - acc: 0.5263 - val_loss: 1.2262 - val_acc: 0.5455\n",
      "Epoch 4/10\n",
      "183/182 [==============================] - 12s 67ms/step - loss: 1.2609 - acc: 0.5371 - val_loss: 1.1866 - val_acc: 0.5503\n",
      "Epoch 5/10\n",
      "183/182 [==============================] - 12s 66ms/step - loss: 1.2368 - acc: 0.5405 - val_loss: 1.1926 - val_acc: 0.5469\n",
      "Epoch 6/10\n",
      "183/182 [==============================] - 12s 67ms/step - loss: 1.2578 - acc: 0.5260 - val_loss: 1.1404 - val_acc: 0.5591\n",
      "Epoch 7/10\n",
      "183/182 [==============================] - 12s 66ms/step - loss: 1.2539 - acc: 0.5215 - val_loss: 1.1796 - val_acc: 0.5476\n",
      "Epoch 8/10\n",
      "183/182 [==============================] - 12s 67ms/step - loss: 1.2400 - acc: 0.5372 - val_loss: 1.1775 - val_acc: 0.5408\n",
      "Epoch 9/10\n",
      "183/182 [==============================] - 13s 68ms/step - loss: 1.2176 - acc: 0.5439 - val_loss: 1.2113 - val_acc: 0.5408\n",
      "Epoch 10/10\n",
      "183/182 [==============================] - 12s 66ms/step - loss: 1.2149 - acc: 0.5377 - val_loss: 1.1716 - val_acc: 0.5476\n"
     ]
    }
   ],
   "source": [
    "history_patch = model_patch.fit_generator(train_gen_patch, steps_per_epoch=train_batch_count/BATCH_SIZE, epochs=10, verbose=1, \n",
    "                              validation_data=val_gen_patch, validation_steps=val_batch_count/BATCH_SIZE)\n",
    "model_patch.save_weights(PATH_SUBMIT_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1646741136260654\n",
      "Test accuracy: 0.561141304347826\n"
     ]
    }
   ],
   "source": [
    "score = model_patch.evaluate_generator(val_gen_patch, steps=val_batch_count/BATCH_SIZE)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modele 2 : fft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850 1463\n",
      "(32, 16, 16, 4)\n"
     ]
    }
   ],
   "source": [
    "train_gen_fft = generator_fft(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen_fft = generator_fft(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)\n",
    "print(train_batch_count, val_batch_count)\n",
    "print(np.shape(train_gen_fft.__next__()[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 16, 16, 4)         16        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        592       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 23)                2967      \n",
      "=================================================================\n",
      "Total params: 846,039\n",
      "Trainable params: 846,031\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (16,16,4)\n",
    "model_fft = Sequential()\n",
    "model_fft.add(BatchNormalization(input_shape=input_shape))\n",
    "model_fft.add(Conv2D(16, kernel_size=(3, 3),activation='relu'))\n",
    "model_fft.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_fft.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_fft.add(Dropout(0.25))\n",
    "model_fft.add(Flatten())\n",
    "model_fft.add(Dense(128, activation='relu'))\n",
    "model_fft.add(Dropout(0.5))\n",
    "model_fft.add(Dense(23, activation='softmax'))\n",
    "\n",
    "model_fft.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_fft.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "183/182 [==============================] - 14s 77ms/step - loss: 1.8291 - acc: 0.3236 - val_loss: 1.4136 - val_acc: 0.4592\n",
      "Epoch 2/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.4581 - acc: 0.4395 - val_loss: 1.3172 - val_acc: 0.4932\n",
      "Epoch 3/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.3516 - acc: 0.4817 - val_loss: 1.3276 - val_acc: 0.5143\n",
      "Epoch 4/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.3340 - acc: 0.5000 - val_loss: 1.2789 - val_acc: 0.5258\n",
      "Epoch 5/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.2986 - acc: 0.5196 - val_loss: 1.2905 - val_acc: 0.5061\n",
      "Epoch 6/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.2925 - acc: 0.5149 - val_loss: 1.2134 - val_acc: 0.5510\n",
      "Epoch 7/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.2717 - acc: 0.5251 - val_loss: 1.2894 - val_acc: 0.5238\n",
      "Epoch 8/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.2848 - acc: 0.5104 - val_loss: 1.2336 - val_acc: 0.5380\n",
      "Epoch 9/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.2512 - acc: 0.5283 - val_loss: 1.2340 - val_acc: 0.5482\n",
      "Epoch 10/10\n",
      "183/182 [==============================] - 13s 73ms/step - loss: 1.2493 - acc: 0.5301 - val_loss: 1.2262 - val_acc: 0.5211\n"
     ]
    }
   ],
   "source": [
    "history_fft = model_fft.fit_generator(train_gen_fft, steps_per_epoch=train_batch_count/BATCH_SIZE, epochs=10, verbose=1, \n",
    "                              validation_data=val_gen_fft, validation_steps=val_batch_count/BATCH_SIZE)\n",
    "model_fft.save_weights(PATH_SUBMIT_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1831893817238186\n",
      "Test accuracy: 0.5686141304347826\n"
     ]
    }
   ],
   "source": [
    "score = model_fft.evaluate_generator(val_gen_fft, steps=val_batch_count/BATCH_SIZE)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modele 3 : histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850 1463\n",
      "(32, 1020)\n"
     ]
    }
   ],
   "source": [
    "train_gen_hist = generator_hist(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen_hist = generator_hist(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)\n",
    "print(train_batch_count, val_batch_count)\n",
    "print(np.shape(train_gen_hist.__next__()[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 1020)              4080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1020)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 23)                23483     \n",
      "=================================================================\n",
      "Total params: 27,563\n",
      "Trainable params: 25,523\n",
      "Non-trainable params: 2,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1020,)\n",
    "model_hist = Sequential()\n",
    "model_hist.add(BatchNormalization(input_shape=input_shape))\n",
    "model_hist.add(Dropout(0.5))\n",
    "model_hist.add(Dense(23, activation='softmax'))\n",
    "\n",
    "model_hist.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_hist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "182/182 [============================>.] - ETA: 0s - loss: 3.2483 - acc: 0.2155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/182 [==============================] - 17s 94ms/step - loss: 3.2441 - acc: 0.2158 - val_loss: 2.1048 - val_acc: 0.3268\n",
      "Epoch 2/10\n",
      "183/182 [==============================] - 16s 90ms/step - loss: 2.3495 - acc: 0.2772 - val_loss: 1.8852 - val_acc: 0.3213\n",
      "Epoch 3/10\n",
      "183/182 [==============================] - 17s 90ms/step - loss: 2.0591 - acc: 0.2971 - val_loss: 1.7393 - val_acc: 0.3478\n",
      "Epoch 4/10\n",
      "183/182 [==============================] - 17s 90ms/step - loss: 1.9306 - acc: 0.3053 - val_loss: 1.6934 - val_acc: 0.3519\n",
      "Epoch 5/10\n",
      "183/182 [==============================] - 16s 90ms/step - loss: 1.8464 - acc: 0.3169 - val_loss: 1.6618 - val_acc: 0.3431\n",
      "Epoch 6/10\n",
      "183/182 [==============================] - 17s 91ms/step - loss: 1.7691 - acc: 0.3388 - val_loss: 1.6808 - val_acc: 0.3485\n",
      "Epoch 7/10\n",
      "183/182 [==============================] - 17s 90ms/step - loss: 1.7697 - acc: 0.3388 - val_loss: 1.6740 - val_acc: 0.3770\n",
      "Epoch 8/10\n",
      "183/182 [==============================] - 17s 90ms/step - loss: 1.7549 - acc: 0.3352 - val_loss: 1.6494 - val_acc: 0.3675\n",
      "Epoch 9/10\n",
      "183/182 [==============================] - 17s 90ms/step - loss: 1.7662 - acc: 0.3342 - val_loss: 1.7067 - val_acc: 0.3444\n",
      "Epoch 10/10\n",
      "183/182 [==============================] - 17s 90ms/step - loss: 1.7414 - acc: 0.3333 - val_loss: 1.6756 - val_acc: 0.3512\n"
     ]
    }
   ],
   "source": [
    "history_hist = model_hist.fit_generator(train_gen_hist, steps_per_epoch=train_batch_count/BATCH_SIZE, epochs=10, verbose=1, \n",
    "                              validation_data=val_gen_hist, validation_steps=val_batch_count/BATCH_SIZE)\n",
    "model_hist.save_weights(PATH_SUBMIT_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modele 4 : texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850 1463\n",
      "(32, 34)\n"
     ]
    }
   ],
   "source": [
    "train_gen_texture = generator_texture(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen_texture = generator_texture(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)\n",
    "print(train_batch_count, val_batch_count)\n",
    "print(np.shape(train_gen_texture.__next__()[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 34)                136       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 23)                805       \n",
      "=================================================================\n",
      "Total params: 941\n",
      "Trainable params: 873\n",
      "Non-trainable params: 68\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (34,)\n",
    "model_texture = Sequential()\n",
    "model_texture.add(BatchNormalization(input_shape=input_shape))\n",
    "model_texture.add(Dropout(0.5))\n",
    "model_texture.add(Dense(23, activation='softmax'))\n",
    "\n",
    "model_texture.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_texture.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "183/182 [==============================] - 11s 60ms/step - loss: 2.7266 - acc: 0.1755 - val_loss: 2.0536 - val_acc: 0.2466\n",
      "Epoch 2/10\n",
      "183/182 [==============================] - 10s 57ms/step - loss: 1.9613 - acc: 0.2522 - val_loss: 1.8167 - val_acc: 0.2806\n",
      "Epoch 3/10\n",
      "183/182 [==============================] - 10s 57ms/step - loss: 1.8388 - acc: 0.2713 - val_loss: 1.7764 - val_acc: 0.2867\n",
      "Epoch 4/10\n",
      "183/182 [==============================] - 10s 57ms/step - loss: 1.8227 - acc: 0.2613 - val_loss: 1.7316 - val_acc: 0.2874\n",
      "Epoch 5/10\n",
      "183/182 [==============================] - 11s 58ms/step - loss: 1.7831 - acc: 0.2654 - val_loss: 1.7317 - val_acc: 0.3240\n",
      "Epoch 6/10\n",
      "183/182 [==============================] - 10s 57ms/step - loss: 1.7852 - acc: 0.2650 - val_loss: 1.7219 - val_acc: 0.3105\n",
      "Epoch 7/10\n",
      "183/182 [==============================] - 10s 57ms/step - loss: 1.7624 - acc: 0.2811 - val_loss: 1.7176 - val_acc: 0.3023\n",
      "Epoch 8/10\n",
      "183/182 [==============================] - 10s 57ms/step - loss: 1.7570 - acc: 0.2891 - val_loss: 1.7133 - val_acc: 0.3139\n",
      "Epoch 9/10\n",
      "183/182 [==============================] - 10s 57ms/step - loss: 1.7501 - acc: 0.2783 - val_loss: 1.7504 - val_acc: 0.2880\n",
      "Epoch 10/10\n",
      "183/182 [==============================] - 10s 57ms/step - loss: 1.7485 - acc: 0.2954 - val_loss: 1.6970 - val_acc: 0.3145\n"
     ]
    }
   ],
   "source": [
    "history_texture = model_texture.fit_generator(train_gen_texture, steps_per_epoch=train_batch_count/BATCH_SIZE, epochs=10, verbose=1, \n",
    "                              validation_data=val_gen_texture, validation_steps=val_batch_count/BATCH_SIZE)\n",
    "model_texture.save_weights(PATH_SUBMIT_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modele 4 : Gabor response filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850 1463\n",
      "(32, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "train_gen_gabor = generator_gabor(PATH_DATA, BATCH_SIZE, train_idxs)\n",
    "train_batch_count = get_batch_count(train_idxs, BATCH_SIZE)\n",
    "\n",
    "val_gen_gabor = generator_gabor(PATH_DATA, BATCH_SIZE, val_idxs)\n",
    "val_batch_count = get_batch_count(val_idxs, BATCH_SIZE)\n",
    "print(train_batch_count, val_batch_count)\n",
    "print(np.shape(train_gen_gabor.__next__()[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 23)                2967      \n",
      "=================================================================\n",
      "Total params: 847,815\n",
      "Trainable params: 847,783\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (16,16,16)\n",
    "model_gabor = Sequential()\n",
    "model_gabor.add(BatchNormalization(input_shape=input_shape))\n",
    "model_gabor.add(Conv2D(16, kernel_size=(3, 3),activation='relu'))\n",
    "model_gabor.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_gabor.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_gabor.add(Dropout(0.25))\n",
    "model_gabor.add(Flatten())\n",
    "model_gabor.add(Dense(128, activation='relu'))\n",
    "model_gabor.add(Dropout(0.5))\n",
    "model_gabor.add(Dense(23, activation='softmax'))\n",
    "\n",
    "model_gabor.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_gabor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "183/182 [==============================] - 92s 501ms/step - loss: 1.5914 - acc: 0.4375 - val_loss: 1.4242 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "183/182 [==============================] - 88s 481ms/step - loss: 1.4511 - acc: 0.4727 - val_loss: 1.3326 - val_acc: 0.5054\n",
      "Epoch 3/10\n",
      "183/182 [==============================] - 88s 480ms/step - loss: 1.4312 - acc: 0.4788 - val_loss: 1.4289 - val_acc: 0.4558\n",
      "Epoch 4/10\n",
      "183/182 [==============================] - 88s 481ms/step - loss: 1.4316 - acc: 0.4788 - val_loss: 1.3431 - val_acc: 0.5088\n",
      "Epoch 5/10\n",
      "183/182 [==============================] - 88s 480ms/step - loss: 1.4296 - acc: 0.4778 - val_loss: 1.3285 - val_acc: 0.5170\n",
      "Epoch 6/10\n",
      "183/182 [==============================] - 88s 480ms/step - loss: 1.4071 - acc: 0.4826 - val_loss: 1.3866 - val_acc: 0.4823\n",
      "Epoch 7/10\n",
      "183/182 [==============================] - 88s 480ms/step - loss: 1.4228 - acc: 0.4819 - val_loss: 1.3418 - val_acc: 0.5054\n",
      "Epoch 8/10\n",
      "183/182 [==============================] - 92s 505ms/step - loss: 1.4051 - acc: 0.4957 - val_loss: 1.3823 - val_acc: 0.5088\n",
      "Epoch 9/10\n",
      "183/182 [==============================] - 91s 497ms/step - loss: 1.3843 - acc: 0.4959 - val_loss: 1.4041 - val_acc: 0.5020\n",
      "Epoch 10/10\n",
      "183/182 [==============================] - 90s 491ms/step - loss: 1.4138 - acc: 0.4807 - val_loss: 1.3470 - val_acc: 0.5082\n"
     ]
    }
   ],
   "source": [
    "history_gabor = model_gabor.fit_generator(train_gen_gabor, steps_per_epoch=train_batch_count/BATCH_SIZE, epochs=10, verbose=1, \n",
    "                              validation_data=val_gen_gabor, validation_steps=val_batch_count/BATCH_SIZE)\n",
    "model_texture.save_weights(PATH_SUBMIT_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction modele 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def prediction_generator_patch(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    \n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        X = []\n",
    "        batch = f['S2'][batch_idxs, :,:,:]\n",
    "        for bb in range(len(batch)):\n",
    "            patch = batch[bb,:,:,:]        \n",
    "            X.append(patch)\n",
    "\n",
    "        yield np.array(X)\n",
    "\n",
    "def build_h5_pred_file(pred, h5_output_path):\n",
    "    if os.path.exists(h5_output_path):\n",
    "        os.remove(h5_output_path)\n",
    "    f = h5.File(h5_output_path, 'w')\n",
    "    top_landcover_submit = f.create_dataset(\"TOP_LANDCOVER\", (len(pred), 1), maxshape=(None, 1))\n",
    "    top_landcover_submit[:, 0] = pred\n",
    "    f.close()\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_generator_fft(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    \n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        X = []\n",
    "        batch = f['S2'][batch_idxs, :,:,:]\n",
    "        for bb in range(len(batch)):\n",
    "            patch = batch[bb,:,:,:]\n",
    "            fft2 = np.zeros((16,16,4))\n",
    "            fft2[:,:,0] = np.real(np.fft.fft2(batch[bb,:,:,0]))\n",
    "            fft2[:,:,1] = np.real(np.fft.fft2(batch[bb,:,:,1]))\n",
    "            fft2[:,:,2] = np.real(np.fft.fft2(batch[bb,:,:,2]))\n",
    "            fft2[:,:,3] = np.real(np.fft.fft2(batch[bb,:,:,3]))\n",
    "            X.append(fft2)\n",
    "            \n",
    "        yield np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_generator_hist(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    \n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        X = []\n",
    "        batch = f['S2'][batch_idxs, :,:,:]\n",
    "        for bb in range(len(batch)):\n",
    "            patch = batch[bb,:,:,:]\n",
    "            band_normalized = []\n",
    "            for i in range(4):\n",
    "                a = batch[bb,:,:,i].flatten()\n",
    "                band_normalized.append((255*((a - np.min(a)) / ( np.max(a) - np.min(a)))).astype(int))\n",
    "\n",
    "            h0, bins = np.histogram(band_normalized[0], bins=range(256))\n",
    "            h1, bins = np.histogram(band_normalized[1], bins=range(256))\n",
    "            h2, bins = np.histogram(band_normalized[2], bins=range(256))\n",
    "            h3, bins = np.histogram(band_normalized[3], bins=range(256))\n",
    "            h = np.concatenate((h0, h1, h2, h3), axis=0)\n",
    "            X.append(h)\n",
    "            \n",
    "        yield np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_generator_texture(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    desc = LocalBinaryPatterns(32, 12)\n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        X = []\n",
    "        batch = f['S2'][batch_idxs, :,:,:]\n",
    "        for bb in range(len(batch)):\n",
    "            gray = cv2.cvtColor(batch[bb,:,:,:], cv2.COLOR_BGR2GRAY)\n",
    "            hist = desc.describe(gray)\n",
    "            X.append(hist)\n",
    "                \n",
    "        yield np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_generator_gabor(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "    kernels = []\n",
    "    for theta in range(4):\n",
    "        theta = theta / 4. * np.pi\n",
    "        for sigma in (1, 3):\n",
    "            for frequency in (0.05, 0.25):\n",
    "                kernel = np.real(gabor_kernel(frequency, theta=theta,\n",
    "                                            sigma_x=sigma, sigma_y=sigma))\n",
    "                kernels.append(kernel)\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        X = []\n",
    "        batch = f['S2'][batch_idxs, :,:,:]\n",
    "        for bb in range(len(batch)):\n",
    "            gray = cv2.cvtColor(batch[bb,:,:,:], cv2.COLOR_BGR2GRAY)\n",
    "            filtered = []\n",
    "            for i in range(len(kernels)):\n",
    "                filtered.append(nd.convolve(gray, kernels[i]))\n",
    "\n",
    "            X.append(filtered)\n",
    "                \n",
    "        yield np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ideas for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241700\n",
      "7554/7554 [==============================] - 82s 11ms/step\n",
      "241700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_idx = get_idxs(PATH_PREDICT_WITHOUT_GT)\n",
    "print(len(pred_idx))\n",
    "pred_gen = prediction_generator_patch(PATH_PREDICT_WITHOUT_GT, BATCH_SIZE, pred_idx)\n",
    "prediction_patch = model_patch.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "print(len(prediction_patch))\n",
    "build_h5_pred_file(np.argmax(prediction_patch, axis = 1), PATH_SUBMIT_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241700\n",
      "7554/7554 [==============================] - 124s 16ms/step\n",
      "241700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_idx = get_idxs(PATH_PREDICT_WITHOUT_GT)\n",
    "print(len(pred_idx))\n",
    "pred_gen = prediction_generator_fft(PATH_PREDICT_WITHOUT_GT, BATCH_SIZE, pred_idx)\n",
    "prediction_fft = model_fft.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "print(len(prediction_fft))\n",
    "build_h5_pred_file(np.argmax(prediction_fft, axis = 1), PATH_SUBMIT_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241700\n",
      "1088/7554 [===>..........................] - ETA: 4:27"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7554/7554 [==============================] - 325s 43ms/step\n",
      "241700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_idx = get_idxs(PATH_PREDICT_WITHOUT_GT)\n",
    "print(len(pred_idx))\n",
    "pred_gen = prediction_generator_hist(PATH_PREDICT_WITHOUT_GT, BATCH_SIZE, pred_idx)\n",
    "prediction_hist = model_hist.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "print(len(prediction_hist))\n",
    "build_h5_pred_file(np.argmax(prediction_hist, axis = 1), PATH_SUBMIT_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241700\n",
      "7554/7554 [==============================] - 142s 19ms/step\n",
      "241700 test_combine_4.h5\n"
     ]
    }
   ],
   "source": [
    "pred_idx = get_idxs(PATH_PREDICT_WITHOUT_GT)\n",
    "print(len(pred_idx))\n",
    "pred_gen = prediction_generator_texture(PATH_PREDICT_WITHOUT_GT, BATCH_SIZE, pred_idx)\n",
    "prediction_texture = model_texture.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "print(len(prediction_texture), PATH_SUBMIT_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241700\n",
      "7554/7554 [==============================] - 2616s 346ms/step\n",
      "241700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_idx = get_idxs(PATH_PREDICT_WITHOUT_GT)\n",
    "print(len(pred_idx))\n",
    "pred_gen = prediction_generator_gabor(PATH_PREDICT_WITHOUT_GT, BATCH_SIZE, pred_idx)\n",
    "prediction_gabor = model_gabor.predict_generator(pred_gen, steps=get_batch_count(pred_idx, BATCH_SIZE), verbose=1)\n",
    "print(len(prediction_gabor))\n",
    "build_h5_pred_file(np.argmax(prediction_gabor, axis = 1), PATH_SUBMIT_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selection des predictions\n",
    "\n",
    "max proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_prediction(prediction_list):\n",
    "    return prediction_list[int(np.floor(np.argmax(prediction_list)/np.shape(prediction_list)[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for i in range(len(prediction_patch)):\n",
    "    tmp = [prediction_patch[i], prediction_fft[i], prediction_hist[i], prediction_texture[i], prediction_gabor[i]]\n",
    "    prediction.append(get_best_prediction(tmp))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gt_generator(h5_path, batch_size, idxs):\n",
    "    f = h5.File(h5_path, 'r')\n",
    "\n",
    "    batch_count = get_batch_count(idxs, batch_size)\n",
    "    \n",
    "    for b in range(batch_count):\n",
    "        batch_idxs = idxs[b*batch_size:(b+1)*batch_size]\n",
    "        batch_idxs = sorted(batch_idxs)\n",
    "        Y = f['TOP_LANDCOVER'][batch_idxs, :]\n",
    "        yield keras.utils.np_utils.to_categorical(np.array(Y), 23)\n",
    "\n",
    "gt_gen = gt_generator(PATH_PREDICT_WITH_GT, BATCH_SIZE, pred_idx)\n",
    "gt = []\n",
    "for elem in gt_gen:\n",
    "    gt.append(elem)\n",
    "gt = np.vstack(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de prediction : 241700\n",
      "nombre de bonne prédiction : 70535\n",
      "taux de reconnaissance : 0.29182871328092674\n"
     ]
    }
   ],
   "source": [
    "nb_ok = 0\n",
    "conf_mat = np.zeros((23,23))\n",
    "for i in range(241700):\n",
    "    conf_mat[int(np.argmax(gt[i]))][int(np.argmax(prediction[i]))] += 1\n",
    "    if np.argmax(gt[i]) == np.argmax(prediction[i]):\n",
    "        nb_ok += 1\n",
    "\n",
    "print(\"nombre de prediction : 241700\")\n",
    "print(\"nombre de bonne prédiction : \" + str(nb_ok))\n",
    "print(\"taux de reconnaissance : \" + str(nb_ok/241700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"480\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display matrix\n",
    "plt.matshow(conf_mat)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
