{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nous avons 18 ratios et 17 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features_label = []\n",
    "\n",
    "path_save = \"../json/features_labelise/\"\n",
    "dirs = os.listdir(path_save)\n",
    "\n",
    "for f in dirs:\n",
    "    #print (\"computing data in : \" + path_save + f)\n",
    "    with open(path_save + f, 'r') as file:\n",
    "        feature = json.load(file)\n",
    "    temp = []\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_1_scale_1\"])\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_1_scale_2\"])\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_2_scale_4\"])\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_1_scale_4\"])\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_2_scale_2\"])\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_2_scale_1\"])\n",
    "    temp.append(feature[\"Ratio_band1_1_band2_3_scale_2\"])\n",
    "    temp.append(feature[\"Ratio_band1_1_band2_3_scale_1\"])\n",
    "    temp.append(feature[\"Ratio_band1_1_band2_3_scale_4\"])\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_3_scale_4\"])\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_3_scale_2\"])\n",
    "    temp.append(feature[\"Ratio_band1_2_band2_3_scale_4\"])\n",
    "    temp.append(feature[\"Ratio_band1_0_band2_3_scale_1\"])\n",
    "    temp.append(feature[\"Ratio_band1_1_band2_2_scale_4\"])\n",
    "    temp.append(feature[\"Ratio_band1_1_band2_2_scale_2\"])\n",
    "    temp.append(feature[\"Ratio_band1_1_band2_2_scale_1\"])\n",
    "    temp.append(feature[\"Ratio_band1_2_band2_3_scale_1\"])\n",
    "    temp.append(feature[\"Ratio_band1_2_band2_3_scale_2\"])\n",
    "    features.append(temp)\n",
    "    features_label.append(feature[\"Label\"])\n",
    "    file.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150510, 18)\n",
      "(150510,)\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features)\n",
    "features_label = np.array(features_label)\n",
    "print features.shape\n",
    "print features_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On fait sur le dataset 80% de train et 20% de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Taille dataset test ', (30102, 18))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, features_label, test_size=0.20)\n",
    "\n",
    "print(\"Taille dataset test \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sur le dataset train on refait 80% de train et 20% de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Taille dataset train ,', (96326, 18))\n",
      "('Taille dataset validation ,', (24082, 18))\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.20)\n",
    "\n",
    "print(\"Taille dataset train ,\", x_train.shape)\n",
    "print(\"Taille dataset validation ,\", x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour l'instant on a une couche cachée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(18,), activation='relu'))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dense(17, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On sauvegarde les poids ( initialisé aléatoirement ) pour pouvoir faire les tests sur les memes poids de départ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "#    weights = layer.get_weights()\n",
    "#    print(weights)\n",
    "model.save_weights('model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vecteur de classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96326, 17)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, 17)\n",
    "y_valid = to_categorical(y_valid, 17)\n",
    "y_test = to_categorical(y_test, 17)\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 117       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 17)                170       \n",
      "=================================================================\n",
      "Total params: 515\n",
      "Trainable params: 515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit sur batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96326 samples, validate on 24082 samples\n",
      "Epoch 1/10\n",
      "96326/96326 [==============================] - 8s - loss: 0.1576 - acc: 0.9467 - val_loss: 0.1439 - val_acc: 0.9482\n",
      "Epoch 2/10\n",
      "96326/96326 [==============================] - 8s - loss: 0.1412 - acc: 0.9486 - val_loss: 0.1404 - val_acc: 0.9486\n",
      "Epoch 3/10\n",
      "96326/96326 [==============================] - 8s - loss: 0.1383 - acc: 0.9493 - val_loss: 0.1380 - val_acc: 0.9491\n",
      "Epoch 4/10\n",
      "96326/96326 [==============================] - 8s - loss: 0.1365 - acc: 0.9498 - val_loss: 0.1365 - val_acc: 0.9493\n",
      "Epoch 5/10\n",
      "96326/96326 [==============================] - 7s - loss: 0.1352 - acc: 0.9500 - val_loss: 0.1352 - val_acc: 0.9495\n",
      "Epoch 6/10\n",
      "96326/96326 [==============================] - 7s - loss: 0.1341 - acc: 0.9503 - val_loss: 0.1342 - val_acc: 0.9502\n",
      "Epoch 7/10\n",
      "96326/96326 [==============================] - 7s - loss: 0.1334 - acc: 0.9505 - val_loss: 0.1350 - val_acc: 0.9495\n",
      "Epoch 8/10\n",
      "96326/96326 [==============================] - 7s - loss: 0.1327 - acc: 0.9507 - val_loss: 0.1331 - val_acc: 0.9502\n",
      "Epoch 9/10\n",
      "96326/96326 [==============================] - 7s - loss: 0.1322 - acc: 0.9508 - val_loss: 0.1325 - val_acc: 0.9506\n",
      "Epoch 10/10\n",
      "96326/96326 [==============================] - 7s - loss: 0.1317 - acc: 0.9511 - val_loss: 0.1321 - val_acc: 0.9507\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train,y_train, epochs=10, batch_size=64,  validation_data=(x_valid, y_valid))\n",
    "model.save_weights('64batch.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit sur batch_size=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96326 samples, validate on 24082 samples\n",
      "Epoch 1/10\n",
      "96326/96326 [==============================] - 14s - loss: 0.1586 - acc: 0.9467 - val_loss: 0.1433 - val_acc: 0.9480\n",
      "Epoch 2/10\n",
      "96326/96326 [==============================] - 14s - loss: 0.1394 - acc: 0.9488 - val_loss: 0.1377 - val_acc: 0.9492\n",
      "Epoch 3/10\n",
      "96326/96326 [==============================] - 14s - loss: 0.1353 - acc: 0.9497 - val_loss: 0.1346 - val_acc: 0.9493\n",
      "Epoch 4/10\n",
      "96326/96326 [==============================] - 15s - loss: 0.1332 - acc: 0.9503 - val_loss: 0.1327 - val_acc: 0.9506\n",
      "Epoch 5/10\n",
      "96326/96326 [==============================] - 13s - loss: 0.1316 - acc: 0.9509 - val_loss: 0.1311 - val_acc: 0.9510\n",
      "Epoch 6/10\n",
      "96326/96326 [==============================] - 13s - loss: 0.1305 - acc: 0.9513 - val_loss: 0.1304 - val_acc: 0.9510\n",
      "Epoch 7/10\n",
      "96326/96326 [==============================] - 15s - loss: 0.1296 - acc: 0.9516 - val_loss: 0.1295 - val_acc: 0.9518\n",
      "Epoch 8/10\n",
      "96326/96326 [==============================] - 14s - loss: 0.1288 - acc: 0.9519 - val_loss: 0.1291 - val_acc: 0.9520\n",
      "Epoch 9/10\n",
      "96326/96326 [==============================] - 13s - loss: 0.1281 - acc: 0.9521 - val_loss: 0.1290 - val_acc: 0.9514\n",
      "Epoch 10/10\n",
      "96326/96326 [==============================] - 13s - loss: 0.1274 - acc: 0.9524 - val_loss: 0.1283 - val_acc: 0.9523\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model.h5')\n",
    "model.fit(x_train,y_train, epochs=10, batch_size=28,  validation_data=(x_valid, y_valid))\n",
    "model.save_weights('28batch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit sur batch_size=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96326 samples, validate on 24082 samples\n",
      "Epoch 1/10\n",
      "96326/96326 [==============================] - 63s - loss: 0.1457 - acc: 0.9480 - val_loss: 0.1360 - val_acc: 0.9485\n",
      "Epoch 2/10\n",
      "96326/96326 [==============================] - 63s - loss: 0.1344 - acc: 0.9494 - val_loss: 0.1340 - val_acc: 0.9497\n",
      "Epoch 3/10\n",
      "96326/96326 [==============================] - 65s - loss: 0.1314 - acc: 0.9503 - val_loss: 0.1303 - val_acc: 0.9502\n",
      "Epoch 4/10\n",
      "96326/96326 [==============================] - 62s - loss: 0.1296 - acc: 0.9510 - val_loss: 0.1285 - val_acc: 0.9511\n",
      "Epoch 5/10\n",
      "96326/96326 [==============================] - 56s - loss: 0.1282 - acc: 0.9515 - val_loss: 0.1287 - val_acc: 0.9514\n",
      "Epoch 6/10\n",
      "96326/96326 [==============================] - 56s - loss: 0.1274 - acc: 0.9518 - val_loss: 0.1270 - val_acc: 0.9518\n",
      "Epoch 7/10\n",
      "96326/96326 [==============================] - 56s - loss: 0.1270 - acc: 0.9520 - val_loss: 0.1267 - val_acc: 0.9521\n",
      "Epoch 8/10\n",
      "96326/96326 [==============================] - 57s - loss: 0.1267 - acc: 0.9522 - val_loss: 0.1263 - val_acc: 0.9521\n",
      "Epoch 9/10\n",
      "96326/96326 [==============================] - 55s - loss: 0.1264 - acc: 0.9522 - val_loss: 0.1257 - val_acc: 0.9525\n",
      "Epoch 10/10\n",
      "96326/96326 [==============================] - 58s - loss: 0.1261 - acc: 0.9523 - val_loss: 0.1260 - val_acc: 0.9522\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model.h5')\n",
    "model.fit(x_train,y_train, epochs=10, batch_size=6,  validation_data=(x_valid, y_valid))\n",
    "model.save_weights('6batch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation sur batch_size=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29888/30102 [============================>.] - ETA: 0s('Test loss:', 0.12479437814108296)\n",
      "('Test accuracy:', 0.95226032933827043)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=x_test, y=y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation sur batch_size=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29664/30102 [============================>.] - ETA: 0s('Test loss:', 0.12682493403677719)\n",
      "('Test accuracy:', 0.95256713076482447)\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('28batch.h5')\n",
    "score = model.evaluate(x=x_test, y=y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation sur batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28992/30102 [===========================>..] - ETA: 0s('Test loss:', 0.13075884387098066)\n",
      "('Test accuracy:', 0.95127544543820908)\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('64batch.h5')\n",
    "score = model.evaluate(x=x_test, y=y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
